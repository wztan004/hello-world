{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789616729/7/ch07lvl1sec55/training-a-logistic-regression-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "n_rows = 30000\n",
    "df = pd.read_csv(\"train.csv\", nrows=n_rows)\n",
    "X = df.drop(['click', 'id', 'hour', 'device_id', 'device_ip'], \n",
    "                                                     axis=1).values\n",
    "Y = df['click'].values\n",
    "n_train = 1000\n",
    "X_train = X[:n_train]\n",
    "Y_train = Y[:n_train]\n",
    "X_test = X[n_train:]\n",
    "Y_test = Y[n_train:]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_enc = enc.fit_transform(X_train)\n",
    "X_test_enc = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(input):\n",
    "    return 1.0 / (1 + np.exp(-input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_sgd(X_train, y_train, weights, \n",
    "                                           learning_rate):\n",
    "    \"\"\" One weight update iteration: moving weights by one step based on each individual sample\n",
    "    Args:\n",
    "    X_train, y_train (numpy.ndarray, training data set)\n",
    "    weights (numpy.ndarray)\n",
    "    learning_rate (float)\n",
    "    Returns:\n",
    "    numpy.ndarray, updated weights\n",
    "    \"\"\"\n",
    "    for X_each, y_each in zip(X_train, y_train):\n",
    "        prediction = compute_prediction(X_each, weights)\n",
    "        weights_delta = X_each.T * (y_each - prediction)\n",
    "        weights += learning_rate * weights_delta\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def compute_cost(X, y, weights):\n",
    "...     \"\"\" Compute the cost J(w)\n",
    "...     Args:\n",
    "...         X, y (numpy.ndarray, data set)\n",
    "...         weights (numpy.ndarray)\n",
    "...     Returns:\n",
    "...         float\n",
    "...     \"\"\"\n",
    "...     predictions = compute_prediction(X, weights)\n",
    "...     cost = np.mean(-y * np.log(predictions)\n",
    "                      - (1 - y) * np.log(1 - predictions))\n",
    "...     return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def compute_prediction(X, weights):\n",
    "...     \"\"\" Compute the prediction y_hat based on current weights\n",
    "...     Args:\n",
    "...         X (numpy.ndarray)\n",
    "...         weights (numpy.ndarray)\n",
    "...     Returns:\n",
    "...         numpy.ndarray, y_hat of X under weights\n",
    "...     \"\"\"\n",
    "...     z = np.dot(X, weights)\n",
    "...     predictions = sigmoid(z)\n",
    "...     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def train_logistic_regression_sgd(X_train, y_train, max_iter, \n",
    "                              learning_rate, fit_intercept=False):\n",
    "...     \"\"\" Train a logistic regression model via SGD\n",
    "...     Args:\n",
    "...     X_train, y_train (numpy.ndarray, training data set)\n",
    "...     max_iter (int, number of iterations)\n",
    "...     learning_rate (float)\n",
    "...     fit_intercept (bool, with an intercept w0 or not)\n",
    "...     Returns:\n",
    "...     numpy.ndarray, learned weights\n",
    "...     \"\"\"\n",
    "...     if fit_intercept:\n",
    "...         intercept = np.ones((X_train.shape[0], 1))\n",
    "...         X_train = np.hstack((intercept, X_train))\n",
    "...     weights = np.zeros(X_train.shape[1])\n",
    "...     for iteration in range(max_iter):\n",
    "...         weights = update_weights_sgd(X_train, y_train, weights, \n",
    "                                                     learning_rate)\n",
    "...         # Check the cost for every 2 (for example) iterations\n",
    "...         if iteration % 2 == 0:\n",
    "...             print(compute_cost(X_train, y_train, weights))\n",
    "...     return weights   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def predict(X, weights):\n",
    "...     if X.shape[1] == weights.shape[0] - 1:\n",
    "...         intercept = np.ones((X.shape[0], 1))\n",
    "...         X = np.hstack((intercept, X))\n",
    "...     return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41983169269579085\n",
      "0.4021233331759999\n",
      "0.3918493614983904\n",
      "0.38399065762361156\n",
      "0.3774836704388587\n",
      "--- 0.172s seconds ---\n",
      "Training samples: 1000, AUC on testing set: 0.684\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "weights = train_logistic_regression_sgd(X_train_enc.toarray(), \n",
    "    Y_train, max_iter=10, learning_rate=0.01, fit_intercept=True)\n",
    "\n",
    "print(\"--- %0.3fs seconds ---\" % \n",
    "                      (timeit.default_timer() - start_time))\n",
    "\n",
    "pred = predict(X_test_enc.toarray(), weights)\n",
    "print('Training samples: {0}, AUC on testing set: {1:.3f}'.format(n_train, roc_auc_score(Y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.linear_model import SGDClassifier\n",
    ">>> sgd_lr = SGDClassifier(loss='log', penalty=None, \n",
    "             fit_intercept=True, n_iter=10, \n",
    "             learning_rate='constant', eta0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tanwz\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1000, AUC on testing set: 0.682\n"
     ]
    }
   ],
   "source": [
    ">>> sgd_lr.fit(X_train_enc.toarray(), Y_train)\n",
    ">>> pred = sgd_lr.predict_proba(X_test_enc.toarray())[:, 1]\n",
    ">>> print('Training samples: {0}, AUC on testing set: {1:.3f}'.format(n_train, roc_auc_score(Y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tanwz\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=None,\n",
       "       n_iter=10, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sgd_lr_l1 = SGDClassifier(loss='log', penalty='l1', alpha=0.0001, \n",
    "                             fit_intercept=True, n_iter=10, \n",
    "                             learning_rate='constant', eta0=0.01)\n",
    ">>> sgd_lr_l1.fit(X_train_enc.toarray(), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.31162825e-02 7.22992299e-02 2.11133851e-01 1.32195846e-01\n",
      "  1.40252709e-01 3.76614751e-02 9.41960760e-03 1.40295772e-01\n",
      "  1.01083968e-02 1.55753667e-03 6.15903358e-03 7.01961347e-03\n",
      "  4.94103500e-02 2.74633403e-02 9.17245788e-04 2.12395575e-02\n",
      "  5.97860863e-04 2.17144122e-02 5.00039561e-03 9.51680698e-03\n",
      "  1.13374230e-02 0.00000000e+00 7.21754264e-03 0.00000000e+00\n",
      "  7.94848432e-02 1.39830542e-03 0.00000000e+00 7.16765310e-03\n",
      "  2.60361525e-02 1.79613267e-02 9.05360469e-03 3.73093433e-04\n",
      "  8.62136409e-03 9.76495365e-02 0.00000000e+00 1.87183675e-02\n",
      "  2.28209434e-02 7.54983234e-04 5.52393588e-02 0.00000000e+00\n",
      "  6.59221110e-02 8.73496197e-03 7.66520004e-02 1.18257538e-02\n",
      "  1.67143253e-02 4.95905934e-04 5.60343673e-02 1.62618099e-01\n",
      "  1.30932217e-01 1.70530279e-01 9.50300513e-02 4.14397650e-03\n",
      "  4.70746557e-02 5.83370303e-03 4.32156405e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.61473436e-02 9.63180174e-02 3.58885217e-02\n",
      "  7.66738298e-03 0.00000000e+00 1.01534632e-02 1.99583459e-02\n",
      "  3.22257239e-02 5.71714986e-02 9.67059525e-03 1.95922093e-02\n",
      "  1.29136669e-03 5.16831698e-02 5.58182639e-03 7.42678823e-02\n",
      "  7.31162825e-02 3.84169506e-02 2.55929002e-01 1.23116220e-01\n",
      "  1.40635121e-01 1.43212342e-01 1.43205062e-03 1.90247543e-03\n",
      "  0.00000000e+00 1.76536755e-02 5.86633941e-02 6.26999492e-02\n",
      "  3.03665842e-02 1.26458544e-02 1.61024360e-03 1.11133615e-02\n",
      "  1.77422203e-03 3.48148289e-02 6.47439953e-04 1.32493523e-02\n",
      "  2.56003832e-05 1.16123950e-03 2.08667305e-02 0.00000000e+00\n",
      "  5.37454731e-03 7.60194550e-02 1.74535476e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.36028275e-02 0.00000000e+00 1.97310938e-02\n",
      "  6.42631255e-03 5.07192024e-02 7.34314771e-02 4.25187594e-01\n",
      "  5.83503539e-02 4.10713588e-03 1.20802665e-02 1.23492783e-01\n",
      "  2.48228404e-03 6.25429279e-02 8.39270265e-03 1.62704194e-02\n",
      "  1.17067757e-02 8.58929679e-03 4.57664740e-03 1.75862201e-02\n",
      "  1.20832310e-01 0.00000000e+00 6.30079569e-02 4.69704167e-03\n",
      "  2.51906679e-02 5.88746802e-02 0.00000000e+00 6.26295655e-02\n",
      "  0.00000000e+00 1.40295772e-01 6.25429279e-02 2.56003832e-05\n",
      "  1.61024360e-03 5.00039561e-03 4.95905934e-04 7.54983234e-04\n",
      "  1.91643640e-01 9.50300513e-02 5.97860863e-04 1.01534632e-02\n",
      "  1.01083968e-02 1.43205062e-03 1.13374230e-02 9.17245788e-04\n",
      "  9.27026991e-02 2.28209434e-02 5.83370303e-03 0.00000000e+00\n",
      "  6.15903358e-03 0.00000000e+00 1.18257538e-02 0.00000000e+00\n",
      "  5.37454731e-03 1.17067757e-02 9.76495365e-02 4.57664740e-03\n",
      "  6.42631255e-03 0.00000000e+00 3.22257239e-02 7.01961347e-03\n",
      "  1.77422203e-03 0.00000000e+00 1.23116220e-01 4.10713588e-03\n",
      "  3.84169506e-02 1.55753667e-03 1.20832310e-01 1.36028275e-02\n",
      "  9.41960760e-03 4.94103500e-02 8.73496197e-03 2.17144122e-02\n",
      "  7.94848432e-02 6.59221110e-02 2.23142014e-02 0.00000000e+00\n",
      "  8.39270265e-03 1.20802665e-02 2.40491944e-02 1.39830542e-03\n",
      "  3.18371715e-02 1.74535476e-02 1.76536755e-02 1.23492783e-01\n",
      "  7.66738298e-03 1.16123950e-03 6.47439953e-04 7.21754264e-03\n",
      "  6.26295655e-02 1.67143253e-02 9.05360469e-03 4.70746557e-02\n",
      "  4.32156405e-02 5.16831698e-02 8.62136409e-03 4.25187594e-01\n",
      "  7.34314771e-02 7.42678823e-02 1.90247543e-03 7.16765310e-03\n",
      "  1.61473436e-02 3.03665842e-02 1.95922093e-02 7.60194550e-02\n",
      "  1.32493523e-02 0.00000000e+00 9.51680698e-03 0.00000000e+00\n",
      "  1.97310938e-02 0.00000000e+00 5.58182639e-03 5.71714986e-02\n",
      "  1.62704194e-02 5.60343673e-02 8.87602939e-02 3.73093433e-04\n",
      "  1.62618099e-01 5.88746802e-02 1.43212342e-01 1.29136669e-03\n",
      "  4.83708058e-02 2.12395575e-02 2.08667305e-02 4.69704167e-03\n",
      "  1.87183675e-02 1.26458544e-02 9.67059525e-03 2.51906679e-02\n",
      "  0.00000000e+00 0.00000000e+00 6.26999492e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.07192024e-02 8.58929679e-03\n",
      "  6.30079569e-02 6.26295655e-02 6.68996062e-02 8.25932980e-04\n",
      "  4.05160961e-02 1.29091356e-01 3.15717579e-02 7.42678823e-02\n",
      "  1.80498237e-01 1.68828009e-01 3.58885217e-02 5.13193267e-02\n",
      "  5.60574617e-03 5.12334772e-02 1.59248984e-01 7.68346862e-03\n",
      "  0.00000000e+00 1.24297466e-01 5.35628241e-03 0.00000000e+00\n",
      "  7.57656890e-03 2.32119201e-03 1.21849938e-01 0.00000000e+00\n",
      "  4.53332381e-03 3.77734930e-03 7.27406446e-02 4.07539054e-03\n",
      "  1.39516759e-03 1.38615399e-02 5.53302964e-02 4.11863592e-02\n",
      "  1.22699497e-02 8.96179399e-02 9.50053318e-04 6.23191871e-02\n",
      "  2.61582163e-03 0.00000000e+00 3.89284752e-02 9.23063956e-03\n",
      "  1.15746458e-03 5.35686661e-03 3.91217503e-02 1.08582243e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.91433028e-03\n",
      "  0.00000000e+00 5.51128543e-02 0.00000000e+00 3.46891039e-03\n",
      "  1.28041699e-02 4.73014083e-03 1.33101360e-02 0.00000000e+00\n",
      "  1.46207797e-02 1.49867029e-01 8.03667953e-02 0.00000000e+00\n",
      "  3.60357946e-02 1.33088811e-02 1.98575360e-02 1.45430636e-02\n",
      "  0.00000000e+00 9.81605477e-03 7.26546913e-03 5.87409925e-02\n",
      "  2.50700682e-02 1.66024571e-02 1.99999997e-03 4.40584331e-03\n",
      "  0.00000000e+00 2.40889069e-03 3.75041782e-03 1.54862677e-01\n",
      "  1.35691453e-03 2.75461819e-02 2.42721896e-03 5.32292715e-02\n",
      "  3.72790635e-02 0.00000000e+00 1.80424899e-02 7.23884346e-02\n",
      "  8.31833054e-02 6.07237693e-04 5.12334772e-02 7.43960090e-02\n",
      "  2.40889069e-03 1.59248984e-01 1.80424899e-02 1.54862677e-01\n",
      "  1.48291389e-01 0.00000000e+00 8.31833054e-02 0.00000000e+00\n",
      "  1.39727362e-02 1.52185535e-02 7.10438953e-02 0.00000000e+00\n",
      "  5.17976124e-02 7.49070064e-06 6.97714302e-02 0.00000000e+00\n",
      "  6.26833266e-02 1.70267756e-01 1.77032370e-01 1.65002492e-01\n",
      "  1.21565428e-02 2.22332255e-02 0.00000000e+00 1.00682891e-02\n",
      "  1.74768244e-03 0.00000000e+00 3.47739499e-02 1.47046380e-02\n",
      "  5.19811343e-03 4.07834648e-03 4.62987449e-03 3.14057205e-02\n",
      "  0.00000000e+00 0.00000000e+00 4.28290424e-03 1.08710291e-02\n",
      "  2.46581071e-02 0.00000000e+00 6.11406865e-03 3.13116005e-02\n",
      "  0.00000000e+00 3.19273831e-03 0.00000000e+00 0.00000000e+00\n",
      "  4.84068166e-02 7.85320509e-03 0.00000000e+00 0.00000000e+00\n",
      "  4.11691927e-02 1.89267915e-02 6.58560383e-03 9.23063956e-03\n",
      "  4.16473272e-03 3.65533450e-02 0.00000000e+00 3.03826294e-03\n",
      "  4.83752183e-02 1.30919165e-02 0.00000000e+00 1.75862201e-02\n",
      "  2.26329281e-02 1.88770355e-02 8.39270265e-03 6.03925826e-02\n",
      "  1.47610424e-01 5.60153408e-02 8.92127827e-03 1.13320619e-01\n",
      "  1.39097194e-01 7.41750903e-02 2.10194434e-02 6.07711235e-03\n",
      "  4.00436896e-02 7.10698664e-02 4.40584331e-03 5.91433028e-03\n",
      "  0.00000000e+00 6.44413286e-03 3.94245075e-02 1.98809176e-02\n",
      "  6.58288948e-02 7.93813964e-03 1.16837164e-01 0.00000000e+00\n",
      "  4.61621001e-02 2.97810663e-02 7.24016854e-04 8.62610686e-03\n",
      "  3.59793239e-02 5.83202851e-03 1.71992516e-02 1.08150897e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.35691453e-03\n",
      "  4.05688534e-02 1.34338268e-02 4.95905934e-04 1.52627229e-03\n",
      "  4.01609269e-02 4.25604076e-02 4.79074705e-03 0.00000000e+00\n",
      "  1.91125741e-02 4.65993655e-02 1.82989890e-02 4.58404192e-02\n",
      "  4.96246699e-02 0.00000000e+00 1.32348916e-01 7.48883975e-02\n",
      "  1.22047575e-03 4.00644372e-03 5.15947242e-02 4.89174366e-02\n",
      "  5.23567691e-02 6.33859901e-03 5.24450122e-03 5.00204347e-04\n",
      "  0.00000000e+00 3.15789873e-03 5.62203892e-02 4.10713588e-03\n",
      "  1.40384006e-02 1.97410129e-02 0.00000000e+00 1.27305099e-01\n",
      "  7.04220288e-02 0.00000000e+00 6.53708216e-03 2.56003832e-05\n",
      "  2.37930581e-02 5.82658905e-02 9.66907970e-03 2.84443951e-02\n",
      "  1.05489047e-02 5.95962347e-02 7.07455954e-02 6.23191871e-02\n",
      "  0.00000000e+00 4.69620966e-02 0.00000000e+00 3.84802028e-02\n",
      "  0.00000000e+00 2.29137401e-02 0.00000000e+00 1.30861115e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.47152156e-03\n",
      "  8.28142526e-03 1.65229920e-02 7.91015289e-02 5.42089845e-03\n",
      "  1.29136669e-03 0.00000000e+00 6.41823900e-03 6.87368759e-02\n",
      "  0.00000000e+00 1.08582243e-02 1.95922093e-02 3.52493752e-03\n",
      "  1.48263320e-02 2.10730292e-01 3.45814795e-03 6.71096355e-04\n",
      "  7.06194235e-02 1.80738857e-02 6.66619896e-03 2.56044403e-03\n",
      "  4.86473651e-02 2.99108827e-03 1.10968991e-01 1.79211665e-01\n",
      "  2.71733571e-02 8.89580548e-03 3.42233719e-02 9.62517466e-03\n",
      "  2.49106199e-02 0.00000000e+00 2.01971857e-02 9.36930945e-02\n",
      "  8.66500327e-04 3.47653754e-03 5.35342359e-02 6.02564083e-02\n",
      "  1.61024360e-03 4.85989997e-02 4.39888494e-03 8.45589084e-02\n",
      "  5.90487120e-02 1.32002289e-02 1.16609568e-01 0.00000000e+00\n",
      "  4.78545219e-02 2.15945841e-01 3.05196548e-02 2.40889069e-03\n",
      "  1.42817264e-03 7.27849877e-02 1.03295018e-02 0.00000000e+00\n",
      "  1.51647655e-02 1.79453794e-02 4.91317097e-03 1.78851203e-02\n",
      "  0.00000000e+00 7.91045597e-02 6.47439953e-04 1.16800656e-02\n",
      "  0.00000000e+00 0.00000000e+00 5.12856668e-03 3.17186858e-02\n",
      "  7.71247412e-02 7.06610597e-03 3.03761270e-02 7.65493716e-02\n",
      "  0.00000000e+00 4.49101491e-03 4.25356843e-02 0.00000000e+00\n",
      "  8.60328408e-04 8.14989689e-04 8.81990076e-03 1.27890662e-02\n",
      "  5.13442645e-03 9.84639461e-02 1.01534632e-02 3.05003534e-02\n",
      "  1.11133615e-02 8.26304610e-02 4.87848419e-03 1.12023292e-02\n",
      "  3.02069330e-01 3.03443150e-02 5.54059605e-03 0.00000000e+00\n",
      "  6.67109264e-03 1.28389389e-02 7.78985629e-03 6.34372627e-02\n",
      "  1.77521656e-02 3.96550928e-02 3.06803575e-03 2.30730412e-02\n",
      "  1.93189626e-02 1.98049419e-02 5.40915491e-03 1.44455746e-02\n",
      "  3.55092609e-03 1.97935299e-02 2.53231314e-03 4.46675706e-03\n",
      "  9.68867117e-03 2.00108401e-03 8.45049413e-05 8.52990433e-03\n",
      "  0.00000000e+00 1.37629358e-02 1.03363303e-03 2.62531921e-02\n",
      "  1.22208111e-02 1.62552248e-02 2.46167050e-03 2.29898379e-01\n",
      "  0.00000000e+00 1.07607182e-01 0.00000000e+00 4.57664740e-03\n",
      "  2.24227558e-02 1.77422203e-03 4.14397650e-03 2.45248793e-02\n",
      "  1.06153759e-01 2.84041407e-04 7.20415092e-02 4.88129156e-02\n",
      "  8.54336962e-03 0.00000000e+00 6.56603578e-03 8.32967659e-02\n",
      "  1.44338945e-02 2.53218360e-02 2.46684137e-02 1.27332354e-02\n",
      "  7.18059791e-02 1.74535476e-02 6.71397874e-02 0.00000000e+00\n",
      "  1.82657424e-02 2.28835619e-02 2.05768075e-01 5.76330463e-03\n",
      "  5.52969642e-03 1.51628150e-02 0.00000000e+00 6.99880678e-02\n",
      "  0.00000000e+00 1.00945312e-02 0.00000000e+00 8.66050661e-02\n",
      "  1.34306330e-02 8.53923771e-03 2.22798253e-02 7.23281812e-02\n",
      "  3.35815565e-02 7.47152599e-05 1.62716579e-02 1.56987889e-02\n",
      "  1.13732583e-03 1.61473436e-02 1.16519396e-03 0.00000000e+00\n",
      "  7.02873900e-03 7.76729203e-02 1.08505470e-02 0.00000000e+00\n",
      "  8.73496197e-03 2.23156356e-03 2.80137189e-02 6.26027043e-02\n",
      "  5.53302964e-02 7.90923602e-03 1.33452388e-03 1.41218913e-01\n",
      "  8.23239544e-02 3.70012923e-03 1.10516282e-02 0.00000000e+00\n",
      "  1.56904147e-02 4.33376479e-02 1.14829461e-03 0.00000000e+00\n",
      "  1.45777971e-02 0.00000000e+00 1.26967954e-02 3.27722012e-03\n",
      "  2.18327881e-02 9.05360469e-03 9.83621353e-02 2.47718899e-03\n",
      "  3.55586466e-02 7.32967980e-02 7.27406446e-02 3.46891039e-03\n",
      "  7.50633426e-02 1.87183675e-02 6.61946088e-02 1.07731756e-03\n",
      "  7.41452959e-02 3.34550531e-02 2.90135183e-02 0.00000000e+00\n",
      "  5.05118134e-02 5.60116580e-02 2.22725732e-02 8.06362007e-03\n",
      "  6.96271353e-02 7.22992299e-02 1.28017569e-01 1.05643266e-01\n",
      "  1.65525795e-02 1.16468982e-01 1.02428584e-01 1.73873787e-01\n",
      "  9.81605477e-03 6.23191871e-02 1.08582243e-02 3.19273831e-03\n",
      "  5.09930247e-02 5.37454731e-03 8.87774819e-03 5.14999942e-02\n",
      "  4.38184235e-02 5.23288888e-03 4.47309664e-02 5.75425493e-02\n",
      "  1.57716637e-02 7.23884346e-02 6.66479773e-03 3.20907533e-03\n",
      "  1.95922093e-02 3.26520625e-02 4.36008912e-02 5.70891282e-01\n",
      "  1.61308011e-02 0.00000000e+00 9.63731235e-02 2.64233886e-01\n",
      "  2.21503678e-01 1.28668847e-02 2.09899673e-01 1.13374230e-02\n",
      "  0.00000000e+00 9.99975261e-04 4.69704167e-03 3.57173662e-02\n",
      "  6.00989964e-02 7.84292147e-02 4.41659566e-02 2.45985161e-02\n",
      "  4.23239013e-02 3.85002574e-02 0.00000000e+00 3.93377815e-02\n",
      "  5.49842756e-02 2.49026482e-01 1.48250490e-02 1.45475421e-02\n",
      "  1.81990512e-02 7.30943278e-02 4.55985042e-02 1.98901904e-02\n",
      "  1.61180635e-01 8.73496197e-03 4.79074705e-03 1.41962018e-02\n",
      "  9.68867117e-03 2.08521597e-02 3.00424899e-02 2.62116120e-01\n",
      "  1.93221509e-02 7.04150533e-02 0.00000000e+00 5.21124376e-02\n",
      "  5.26171319e-02 1.16983049e-01 0.00000000e+00 4.32487964e-04\n",
      "  0.00000000e+00 5.23372103e-02 4.88682664e-02 6.99605484e-02\n",
      "  3.55701006e-02 4.89174366e-02 1.57421351e-02 3.03826294e-03\n",
      "  2.62531921e-02 1.20877365e-01 2.35144630e-02 6.59420197e-02\n",
      "  1.44890420e-02 3.84964176e-02 1.70227983e-02 3.03798064e-02\n",
      "  2.90942402e-02 2.55031992e-02 9.80813055e-02 2.22011350e-02\n",
      "  1.06257001e-01 1.37372430e-01 5.24450122e-03 2.15479318e-02\n",
      "  7.93022658e-03 2.40847006e-03 1.70717949e-02 1.13761648e-02\n",
      "  6.41823900e-03 5.60574617e-03 7.51592315e-02 1.96976598e-01\n",
      "  3.91091011e-02 1.31089747e-01 1.08632459e-01 1.73062906e-01\n",
      "  6.57860143e-02 1.01534632e-02 6.04399163e-02 1.51647655e-02\n",
      "  1.75862201e-02 4.50318222e-02 8.49981316e-02 2.27880494e-01\n",
      "  4.50318222e-02 2.97671844e-01 1.54789482e-01 4.25031323e-02\n",
      "  1.08582243e-02 3.19273831e-03 5.09930247e-02 5.37454731e-03\n",
      "  1.19617749e-03 5.23288888e-03 4.47309664e-02 5.75425493e-02\n",
      "  1.57716637e-02 1.41962018e-02 7.23884346e-02 6.66479773e-03\n",
      "  3.20907533e-03 2.59099347e-01 3.03798064e-02 3.03826294e-03\n",
      "  1.13374230e-02 4.98327360e-02 9.99975261e-04 5.49842756e-02\n",
      "  4.69704167e-03 9.66584460e-02 1.37372430e-01 7.84292147e-02\n",
      "  4.23239013e-02 6.38546277e-02 2.45985161e-02 3.85002574e-02\n",
      "  3.93377815e-02 7.30943278e-02 3.04624986e-01 0.00000000e+00\n",
      "  1.81990512e-02 1.98901904e-02 1.61180635e-01 8.73496197e-03\n",
      "  4.79074705e-03 2.08521597e-02 3.00424899e-02 2.26612921e-01\n",
      "  4.10929023e-02 1.12826365e-01 5.99651621e-02 5.26171319e-02\n",
      "  4.32487964e-04 0.00000000e+00 4.88682664e-02 6.99605484e-02\n",
      "  3.55701006e-02 4.89174366e-02 1.57421351e-02 8.46241730e-02\n",
      "  3.54429794e-02 2.90942402e-02 3.94781584e-02 5.24450122e-03\n",
      "  1.82137172e-01 2.40847006e-03 1.70717949e-02 2.71098371e-01\n",
      "  4.31352464e-02 1.96976598e-01 3.91091011e-02 1.73062906e-01\n",
      "  1.51647655e-02 4.80736524e-03 1.75862201e-02 2.23951240e-01\n",
      "  3.06075213e-02 2.23055459e-01 1.46410883e-01 4.16742883e-02\n",
      "  9.53521219e-02 1.81990512e-02 1.75862201e-02 0.00000000e+00\n",
      "  1.56175454e-02 5.22275349e-02 1.48722303e-01 4.79074705e-03\n",
      "  2.71098371e-01 1.13374230e-02 3.00424899e-02 1.47867496e-01\n",
      "  4.67724238e-02 1.59267423e-02 7.84292147e-02 3.94781584e-02\n",
      "  1.37372430e-01 4.32487964e-04 1.47962479e-01 5.24450122e-03\n",
      "  3.03798064e-02 3.04624986e-01 1.57716637e-02 2.16449081e-02\n",
      "  3.03826294e-03 1.41962018e-02 7.49326035e-02 4.28397271e-02\n",
      "  0.00000000e+00 3.07687420e-03 7.06194235e-02 2.37667432e-02\n",
      "  1.79453794e-02 2.49461519e-02 1.58129040e-02 1.37372430e-01\n",
      "  1.29938543e-01 3.20907533e-03 0.00000000e+00 8.87774819e-03\n",
      "  1.11712416e-03 1.81990512e-02 1.47330479e-02 7.10362275e-03\n",
      "  3.74853691e-03 7.56271605e-02 1.95328704e-01 3.78346334e-02\n",
      "  9.37210037e-02 0.00000000e+00 1.06199028e-01 2.11428773e-01\n",
      "  1.35269701e-01 1.70717949e-02 5.06512947e-02 2.04050342e-02\n",
      "  1.47867496e-01 6.32219921e-02 2.67253361e-02 1.13636542e-02\n",
      "  1.26347884e-01 6.78517861e-03 1.75862201e-02 3.94194368e-02\n",
      "  0.00000000e+00 5.15947242e-02 1.29224362e-02 3.45814795e-03\n",
      "  3.41261539e-03 4.01609269e-02 4.94505795e-02 8.39270265e-03\n",
      "  6.31806889e-02 3.86263941e-02 3.82949133e-02 2.32090721e-02\n",
      "  8.20319734e-02 1.79613267e-02 2.71098371e-01 1.49044080e-02\n",
      "  1.28280325e-02 8.45216976e-03 8.35159527e-02 2.22694720e-01\n",
      "  7.18857099e-02 1.70715263e-01 1.75862201e-02 5.47226596e-02\n",
      "  1.71433230e-01 5.99651621e-02 2.06212048e-01 7.91077787e-02\n",
      "  2.59099347e-01 2.99261710e-02 1.13374230e-02 3.03798064e-02\n",
      "  1.37372430e-01 4.79074705e-03 2.61492120e-01 2.41208181e-01\n",
      "  2.72055900e-01]]\n"
     ]
    }
   ],
   "source": [
    ">>> coef_abs = np.abs(sgd_lr_l1.coef_)\n",
    ">>> print(coef_abs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    ">>> print(np.sort(coef_abs)[0][:10])\n",
    ">>> bottom_10 = np.argsort(coef_abs)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 least important features are:\n",
      " ['x8_beb6d112' 'x8_96b83ebe' 'x8_fd621b1f' 'x8_9d21b1a9' 'x5_f4510c5e'\n",
      " 'x8_9ea0eb04' 'x2_f5476ff8' 'x6_813f3323' 'x17_100002' 'x8_f16efb5e']\n"
     ]
    }
   ],
   "source": [
    ">>> feature_names = enc.get_feature_names()\n",
    ">>> print('10 least important features are:\\n', \n",
    "                                   feature_names[bottom_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27109837 0.27109837 0.2720559  0.29767184 0.30206933 0.30462499\n",
      " 0.30462499 0.42518759 0.42518759 0.57089128]\n",
      "10 most important features are:\n",
      " ['x17_100228' 'x16_171' 'x18_157' 'x13_50' 'x8_a5bce124' 'x16_1063'\n",
      " 'x14_1993' 'x3_98572c79' 'x2_d9750ee7' 'x11_15701']\n"
     ]
    }
   ],
   "source": [
    ">>> print(np.sort(coef_abs)[0][-10:])\n",
    ">>> top_10 = np.argsort(coef_abs)[0][-10:]\n",
    ">>> print('10 most important features are:\\n', feature_names[top_10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
